# -*- coding: utf-8 -*-
"""tst3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NLI4exOG-GBIc6cIxTyVJXTlhGB71VSf
"""

! pip install pyspark

# ### **Exercise: Working with Key-Value Pair RDDs in PySpark**
sales_data = [
    ("ProductA", 100),
    ("ProductB", 150),
    ("ProductA", 200),
    ("ProductC", 300),
    ("ProductB", 250),
    ("ProductC", 100)
]
regional_sales_data = [
    ("ProductA", 50),
    ("ProductC", 150)
]

from pyspark.sql import SparkSession
from operator import add

# Initialize SparkSession and SparkContext
spark = SparkSession.builder.appName("Key-Value Pair RDD Exercise").getOrCreate()
sc = spark.sparkContext

# Dataset
sales_data = [
    ("ProductA", 100),
    ("ProductB", 150),
    ("ProductA", 200),
    ("ProductC", 300),
    ("ProductB", 250),
    ("ProductC", 100)
]

regional_sales_data = [
    ("ProductA", 50),
    ("ProductC", 150)
]

# Step 2: Create and Explore the RDD
# Task 1: Create an RDD from the Sales Data
sales_rdd = sc.parallelize(sales_data)
print("First few elements of the RDD:")
print(sales_rdd.take(3))

# Step 3: Grouping and Aggregating Data
# Task 2: Group Data by Product Name
grouped_sales = sales_rdd.groupByKey()
print("\nGrouped data structure:")
print(grouped_sales.mapValues(list).collect())

# Task 3: Calculate Total Sales by Product
total_sales = sales_rdd.reduceByKey(add)
print("\nTotal sales for each product:")
print(total_sales.collect())

# Task 4: Sort Products by Total Sales
sorted_sales = total_sales.sortBy(lambda x: x[1], ascending=False)
print("\nSorted list of products by sales:")
print(sorted_sales.collect())

# Step 4: Additional Transformations
# Task 5: Filter Products with High Sales
high_sales = total_sales.filter(lambda x: x[1] > 200)
print("\nProducts with sales greater than 200:")
print(high_sales.collect())

# Task 6: Combine Regional Sales Data
regional_rdd = sc.parallelize(regional_sales_data)
combined_sales = sales_rdd.union(regional_rdd)
new_total_sales = combined_sales.reduceByKey(add)
print("\nCombined sales data:")
print(new_total_sales.collect())

# Step 5: Perform Actions on the RDD
# Task 7: Count the Number of Distinct Products
distinct_products = sales_rdd.keys().distinct().count()
print(f"\nNumber of distinct products: {distinct_products}")

# Task 8: Identify the Product with Maximum Sales
max_sales_product = new_total_sales.reduce(lambda x, y: x if x[1] > y[1] else y)
print(f"\nProduct with maximum sales: {max_sales_product[0]}, Amount: {max_sales_product[1]}")

# Challenge Task: Calculate the Average Sales per Product
sales_count = sales_rdd.mapValues(lambda x: (x, 1)).reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))
avg_sales = sales_count.mapValues(lambda x: x[0] / x[1])
print("\nAverage sales for each product:")
print(avg_sales.collect())

