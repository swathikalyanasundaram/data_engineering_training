# -*- coding: utf-8 -*-
"""task2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gGpixzjpuFk_qGp641TrK5Da7_slm2tZ
"""

! pip install pyspark

from pyspark.sql import SparkSession

#Create a spark session
spark=SparkSession.builder \
  .appName("EmployeeSalaryETL") \
  .getOrCreate()

import pandas as pd
data = {
    "name": ["John", "Jane", "Mike", "Emily"],
    "age": [28, 32, 45, 23],
    "gender": ["Male", "Female", "Male", "Female"],
    "salary":[1000,2000,3000,4000]
}

df = pd.DataFrame(data)

csv_file_path = "/content/sample_people.csv"
df.to_csv(csv_file_path, index=False)

print("csv file is created at:{csv_file_path}")

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, avg, round

# Step 1: Initialize Spark session
spark = SparkSession.builder.appName("EmployeeSalaryETL").getOrCreate()

# Step 2: Load the CSV file into a DataFrame
df = spark.read.csv(csv_file_path, header=True, inferSchema=True)

# Step 3: Show the raw data
df.show()
df.printSchema()  # To check the schema of the loaded DataFrame

import pandas as pd
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg

# Transform
# 1. Filter: Include only employees aged 30 and above
df_filtered = df.filter(col("age") >= 30)

# 2. Add New Column: Calculate 10% bonus
df_with_bonus = df.withColumn("salary_with_bonus", col("salary") * 1.1)

# 3. Aggregation: Compute average salary by gender
avg_salary_by_gender = df_filtered.groupBy("gender").agg(avg("salary").alias("avg_salary"))

# Load: Save the transformed data to Parquet

# Path to the saved Parquet file
parquet_file_path = "/content/employee_data.parquet"

# Load the Parquet file into a DataFrame
df_loaded = spark.read.parquet(parquet_file_path)

# Show the loaded data
df_loaded.show()

print("Employees aged 30:")
df_filtered.show()

print("Employees salary with bonus:")
df_with_bonus.show()

print("\nAverage salary by gender:")
avg_salary_by_gender.show()